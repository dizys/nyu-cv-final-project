{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JxmgIMoT9geY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from fastai.data.all import *\n",
        "from fastai.vision.all import *\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import os\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHkenVTD4o73",
        "outputId": "60f91bb5-1857-449b-a24b-335b66e9ad59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-14 07:42:54--  https://github.com/dizys/nyu-cv-final-project/releases/download/dataset/NYU_CV_RVAP_dataset_1.0.0.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/562663291/80ea1b67-1834-4f92-8926-b144ae2ab80a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T074254Z&X-Amz-Expires=300&X-Amz-Signature=24974d22d6a05ddfde5fb384c22c07539e934c827b2baa36d431aa0b36c9d28e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=562663291&response-content-disposition=attachment%3B%20filename%3DNYU_CV_RVAP_dataset_1.0.0.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-14 07:42:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/562663291/80ea1b67-1834-4f92-8926-b144ae2ab80a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T074254Z&X-Amz-Expires=300&X-Amz-Signature=24974d22d6a05ddfde5fb384c22c07539e934c827b2baa36d431aa0b36c9d28e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=562663291&response-content-disposition=attachment%3B%20filename%3DNYU_CV_RVAP_dataset_1.0.0.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 455631533 (435M) [application/octet-stream]\n",
            "Saving to: ‘NYU_CV_RVAP_dataset_1.0.0.zip’\n",
            "\n",
            "NYU_CV_RVAP_dataset 100%[===================>] 434.52M  42.1MB/s    in 8.4s    \n",
            "\n",
            "2022-12-14 07:43:03 (51.6 MB/s) - ‘NYU_CV_RVAP_dataset_1.0.0.zip’ saved [455631533/455631533]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O NYU_CV_RVAP_dataset_1.0.0.zip https://github.com/dizys/nyu-cv-final-project/releases/download/dataset/NYU_CV_RVAP_dataset_1.0.0.zip\n",
        "!mkdir -p /content/dataset/stable_diffusion\n",
        "!unzip -qq NYU_CV_RVAP_dataset_1.0.0.zip -d /content/dataset/stable_diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGjKMyI7993-",
        "outputId": "e4985512-2175-4c8e-a918-84fd0b38de2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-14 08:00:53--  https://github.com/dizys/nyu-cv-final-project/releases/download/dataset/NYU_CV_RVAP_dalle2_dataset_1.1.0.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/562663291/ba6488ff-ea67-4a04-9c69-b01ba899a80e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T080054Z&X-Amz-Expires=300&X-Amz-Signature=c73a38cbe9a226a34691527ad03cc42cb8da6092c3dd46763526edb259c5616e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=562663291&response-content-disposition=attachment%3B%20filename%3DNYU_CV_RVAP_dalle2_dataset_1.1.0.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-14 08:00:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/562663291/ba6488ff-ea67-4a04-9c69-b01ba899a80e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T080054Z&X-Amz-Expires=300&X-Amz-Signature=c73a38cbe9a226a34691527ad03cc42cb8da6092c3dd46763526edb259c5616e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=562663291&response-content-disposition=attachment%3B%20filename%3DNYU_CV_RVAP_dalle2_dataset_1.1.0.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16702899 (16M) [application/octet-stream]\n",
            "Saving to: ‘NYU_CV_RVAP_dalle2_dataset_1.1.0.zip’\n",
            "\n",
            "NYU_CV_RVAP_dalle2_ 100%[===================>]  15.93M  40.3MB/s    in 0.4s    \n",
            "\n",
            "2022-12-14 08:00:54 (40.3 MB/s) - ‘NYU_CV_RVAP_dalle2_dataset_1.1.0.zip’ saved [16702899/16702899]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O NYU_CV_RVAP_dalle2_dataset_1.1.0.zip https://github.com/dizys/nyu-cv-final-project/releases/download/dataset/NYU_CV_RVAP_dalle2_dataset_1.1.0.zip\n",
        "!mkdir -p /content/dataset/dalle2\n",
        "!unzip -qq NYU_CV_RVAP_dalle2_dataset_1.1.0.zip -d /content/dataset/dalle2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zhlUZLXVAk2l"
      },
      "outputs": [],
      "source": [
        "def label_func(fpath: Path):\n",
        "  label = \"original\" if \"original/\" in str(fpath.absolute()) else \"ai\"\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "Z9bNvogi-E2P",
        "outputId": "3a801a4a-3ff4-4868-b2ba-5a95e4c17a50"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(blocks    = (ImageBlock, CategoryBlock),\n",
        "                   get_items = get_image_files,\n",
        "                   get_y     = label_func,\n",
        "                   splitter  = RandomSplitter())\n",
        "\n",
        "dls = dblock.dataloaders(\"dataset/stable_diffusion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sovl546HFLk2"
      },
      "outputs": [],
      "source": [
        "test_set_image_paths = glob(\"/content/dataset/dalle2/**/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zKiREm9VGKf6"
      },
      "outputs": [],
      "source": [
        "test_dl = dls.test_dl(test_set_image_paths, with_labels=False, label_func=label_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwN6m-LrA-8E",
        "outputId": "9ed154c6-bd08-4070-c9b9-38f06487b19b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "learn = vision_learner(dls, resnet34, metrics=accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "576WMQp1SKKc"
      },
      "outputs": [],
      "source": [
        "models_path = Path(\"/content/drive/MyDrive/Studies/Master Studies/Fall 2022/Computer Vision/Final Project/models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSMPDOGSREZJ",
        "outputId": "f7b03236-7303-405a-887c-33694f29fc80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f49bf3acc70>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learn.load(models_path / \"resnet34\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cs4ucZx4Gl1m",
        "outputId": "4ff7b33c-665f-4163-e81d-6262c6f6ea2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TensorBase(1)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_, _, preds = learn.get_preds(dl=test_dl, with_decoded=True)\n",
        "preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "OcYDU8dm90Kf",
        "outputId": "cc32fb1b-c0a1-4ce9-aba6-8f719fa9f557"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1248' class='' max='1248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1248/1248 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_total = 0\n",
        "dataset_correct_prediction = 0\n",
        "dataset_ai_as_original = 0\n",
        "dataset_original_as_ai = 0\n",
        "dataset_ai_as_ai = 0\n",
        "dataset_original_as_original = 0\n",
        "\n",
        "for i in progress_bar(range(len(test_set_image_paths))):\n",
        "  image_path = test_set_image_paths[i]\n",
        "  ground_truth = label_func(Path(image_path))\n",
        "  prediction = \"original\" if preds[i].item() == 1 else \"ai\" \n",
        "  dataset_total += 1\n",
        "  if ground_truth == prediction:\n",
        "    dataset_correct_prediction += 1\n",
        "    if ground_truth == \"original\":\n",
        "      dataset_original_as_original += 1\n",
        "    else:\n",
        "      dataset_ai_as_ai += 1\n",
        "  else:\n",
        "    if ground_truth == \"original\":\n",
        "      dataset_original_as_ai += 1\n",
        "    else:\n",
        "      dataset_ai_as_original += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0UgB2yt96pH",
        "outputId": "8c8cf928-bbdc-4fc4-a573-d498543f13eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 637/1248 = 0.5104166666666666\n",
            "TN = 620 original images correctly detected.\n",
            "TP = 17 ai images correctly detected.\n",
            "FP = 4 original images falsly detected as ai ones.\n",
            "FN = 607 ai images falsly detected as original ones.\n",
            "Accuracy: 0.5104166666666666\n",
            "Precision: 0.8095238095238095\n",
            "Recall: 0.027243589743589744\n",
            "F1: 0.05271317829457364\n"
          ]
        }
      ],
      "source": [
        "TP = dataset_ai_as_ai\n",
        "FP = dataset_original_as_ai\n",
        "FN = dataset_ai_as_original\n",
        "TN = dataset_original_as_original\n",
        "\n",
        "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Accuracy: {dataset_correct_prediction}/{dataset_total} = {dataset_correct_prediction/dataset_total}\")\n",
        "print(f\"TN = {dataset_original_as_original} original images correctly detected.\")\n",
        "print(f\"TP = {dataset_ai_as_ai} ai images correctly detected.\")\n",
        "print(f\"FP = {dataset_original_as_ai} original images falsly detected as ai ones.\")\n",
        "print(f\"FN = {dataset_ai_as_original} ai images falsly detected as original ones.\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRHNUXjREWTb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, May 24 2022, 21:13:51) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1ee31c6c04734c987ff4a07998981bec76a7722be9d71d6274aa78d7ce29c5f4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
